{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f691ab815dbc454094008c8fd85b7dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11060b31405444bead662a981366ff80",
              "IPY_MODEL_2e9205f57951491d942d15bb1787fddf",
              "IPY_MODEL_6627dea468a9453aab6b8eb1b0b5925b"
            ],
            "layout": "IPY_MODEL_4a9c76f717a944a1b5ae0fcb76449563"
          }
        },
        "11060b31405444bead662a981366ff80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6198969e50a741c39f714d33a807a77c",
            "placeholder": "​",
            "style": "IPY_MODEL_c0ca4e7ce98e4969bc67f6f8e3b7d55f",
            "value": "100%"
          }
        },
        "2e9205f57951491d942d15bb1787fddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8301b2d5efc04305aa36c3c8c3ac3636",
            "max": 14640,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fb25c50bff94798874baa2dcd532d83",
            "value": 14640
          }
        },
        "6627dea468a9453aab6b8eb1b0b5925b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecbc5dcdf64c432fb42bd8f76fffc9e2",
            "placeholder": "​",
            "style": "IPY_MODEL_6d4e1b4e7d5a415da9c054e51b156221",
            "value": " 14640/14640 [00:02&lt;00:00, 6351.96it/s]"
          }
        },
        "4a9c76f717a944a1b5ae0fcb76449563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6198969e50a741c39f714d33a807a77c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ca4e7ce98e4969bc67f6f8e3b7d55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8301b2d5efc04305aa36c3c8c3ac3636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb25c50bff94798874baa2dcd532d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecbc5dcdf64c432fb42bd8f76fffc9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4e1b4e7d5a415da9c054e51b156221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPV6GD0oXtQk"
      },
      "source": [
        "# Objective\n",
        "\n",
        "In this notebook, we will fine-tune a pre-trained BERT model to perform sentiment analysis on a twitter data.\n",
        "\n",
        "# Table of Contents\n",
        "\n",
        "1. Setup\n",
        "  - Using Google Colab for training\n",
        "  - Installing the Hugging Face's Transformers Library\n",
        "2. Loading & Understanding BERT\n",
        "  - Download Pretrained BERT model\n",
        "  - Tokenization and Input Formatting\n",
        "  - Understanding Input and Output\n",
        "3. Preparing Data\n",
        "  - Loading and Reading Twitter Airline\n",
        "  - Text Cleaning\n",
        "  - Preparing Input and Output Data\n",
        "  - Training and Validation Data\n",
        "  - Define Dataloaders\n",
        "4. Model Finetuning\n",
        "  - Approach: Fine-Tuning Only Head\n",
        "  - Define Model Architecture\n",
        "  - Define Optimizer and Loss function\n",
        "  - Model Training and Evaluation\n",
        "  - Train the Model\n",
        "  - Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plFhDqWS7IDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb7ce06-4c79-47ec-d4d0-89e2485c1c84"
      },
      "source": [
        "#import torch library\n",
        "import torch\n",
        "\n",
        "# check GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    # select GPU\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "device"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qksck1C7e3I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b958dd92-7570-4e99-d010-c3751fe1cb96"
      },
      "source": [
        "# check GPU name\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_jdjScBvG-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88d3c23-ef66-4738-c6ef-582082deea0e"
      },
      "source": [
        "#install hugging face transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZGp7pmiIa42"
      },
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# download bert pretrained model\n",
        "bert = BertModel.from_pretrained('bert-base-uncased',return_dict=False)"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCZVXkA30cf9"
      },
      "source": [
        "#importing fast \"BERT\" tokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WosuQLl15olj"
      },
      "source": [
        "**Steps Followed for Input Formatting**\n",
        "\n",
        "1. Tokenization\n",
        "\n",
        "2. Special Tokens\n",
        "\n",
        "  * Prepend the `[CLS]` token to the start of the sequence.\n",
        "  * Append the `[SEP]` token to the end of the sequence.\n",
        "\n",
        "3. Pad sequences\n",
        "\n",
        "4. Converting tokens to integers\n",
        "\n",
        "5. Create Attention masks to avoid pad tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQj1-E2pQY6H"
      },
      "source": [
        "#3. Preparing Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFGQamTe3ebu"
      },
      "source": [
        "\n",
        "##3.1 Loading and Reading Twitter Airline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpHLW3M3KJEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "50eddcc6-5529-4ea4-cd88-db314cdcdc61"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# increase the output column width\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "# read CSV file\n",
        "df = pd.read_csv('/content/Tweets.csv')\n",
        "\n",
        "# print first 5 rows\n",
        "df.head()"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                                                                                             text  \\\n",
              "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
              "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
              "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
              "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
              "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
              "\n",
              "  tweet_coord              tweet_created tweet_location  \\\n",
              "0         NaN  2015-02-24 11:35:52 -0800            NaN   \n",
              "1         NaN  2015-02-24 11:15:59 -0800            NaN   \n",
              "2         NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
              "3         NaN  2015-02-24 11:15:36 -0800            NaN   \n",
              "4         NaN  2015-02-24 11:14:45 -0800            NaN   \n",
              "\n",
              "                user_timezone  \n",
              "0  Eastern Time (US & Canada)  \n",
              "1  Pacific Time (US & Canada)  \n",
              "2  Central Time (US & Canada)  \n",
              "3  Pacific Time (US & Canada)  \n",
              "4  Pacific Time (US & Canada)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a38777a7-95f9-423f-9dbc-af835aee8dc3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a38777a7-95f9-423f-9dbc-af835aee8dc3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a38777a7-95f9-423f-9dbc-af835aee8dc3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a38777a7-95f9-423f-9dbc-af835aee8dc3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e989fcc1-ba55-4103-bf27-2446b2ca63a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e989fcc1-ba55-4103-bf27-2446b2ca63a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e989fcc1-ba55-4103-bf27-2446b2ca63a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzLKBEuUKJAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d9cd36-4a5c-4976-bcf5-2973b8afd058"
      },
      "source": [
        "#shape of the dataframe\n",
        "df.shape"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GirJa9_sWJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e190e7d-7a7b-4eaf-ec4c-1ad95d60e031"
      },
      "source": [
        "# class distribution\n",
        "df['airline_sentiment'].value_counts()"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWcEVUWIMGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec351bc6-a944-42ac-e7f4-867ad2d0f4a8"
      },
      "source": [
        "# class distribution\n",
        "df['airline_sentiment'].value_counts(normalize = True)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    0.626913\n",
              "neutral     0.211680\n",
              "positive    0.161407\n",
              "Name: airline_sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ArDZS9tVuPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae1630d-0ff5-441a-e73f-a165e247d406"
      },
      "source": [
        "# saving the value counts to a list\n",
        "class_counts = df['airline_sentiment'].value_counts().tolist()\n",
        "class_counts"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9178, 3099, 2363]"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWWstFVe3x00"
      },
      "source": [
        "##3.2 Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ol7s5sTGUgj"
      },
      "source": [
        "#library for pattern matching\n",
        "import re\n",
        "\n",
        "#define a function for text cleaning\n",
        "def preprocessor(text):\n",
        "\n",
        "  #convering text to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  #remove user mentions\n",
        "  text = re.sub(r'@[A-Za-z0-9]+','',text)\n",
        "\n",
        "  #remove hashtags\n",
        "  #text = re.sub(r'#[A-Za-z0-9]+','',text)\n",
        "\n",
        "  #remove links\n",
        "  text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "  #split token to remove extra spaces\n",
        "  tokens = text.split()\n",
        "\n",
        "  #join tokens by space\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykLsz50lCnXC"
      },
      "source": [
        "# perform text cleaning\n",
        "df['clean_text']= df['text'].apply(preprocessor)"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEnvlwJdz9-t"
      },
      "source": [
        "# save cleaned text and labels to a variable\n",
        "text   = df['clean_text'].values\n",
        "labels = df['airline_sentiment'].values"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7qq7aLst01a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f38c72-35f0-49b4-f5b2-c2c2c221a204"
      },
      "source": [
        "#cleaned text\n",
        "text[50:55]"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['is flight 769 on it\\'s way? was supposed to take off 30 minutes ago. website still shows \"on time\" not \"in flight\". thanks.',\n",
              "       'julie andrews all the way though was very impressive! no to',\n",
              "       'wish you flew out of atlanta... soon?',\n",
              "       'julie andrews. hands down.',\n",
              "       'will flights be leaving dallas for la on february 24th?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnbVmXPN_ao6"
      },
      "source": [
        "##3.3 Preparing Input and Output Data\n",
        "\n",
        "\n",
        "**Preparing Output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqzd8-2P0l3T"
      },
      "source": [
        "#importing label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#define label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "#fit and transform target strings to a numbers\n",
        "labels = le.fit_transform(labels)"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhOF8XUDWuHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ea2ef2-9f5a-4497-a6ac-6c36250263f7"
      },
      "source": [
        "#classes\n",
        "le.classes_"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBFVkRgoDX_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5c1ac2-3cf0-477a-c7e2-f8fa6b90af27"
      },
      "source": [
        "labels"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKh8Rcuw_vOt"
      },
      "source": [
        "**Preparing Input Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eUFCQkM0-Nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "bd502258-6f4e-4a01-97b3-7bd578a8db24"
      },
      "source": [
        "# library for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# compute no. of words in each tweet\n",
        "num = [len(i.split()) for i in text]\n",
        "\n",
        "plt.hist(num, bins = 30)\n",
        "\n",
        "plt.title(\"Histogram: Length of sentences\")"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Histogram: Length of sentences')"
            ]
          },
          "metadata": {},
          "execution_count": 182
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0bMmY6M0-Zs"
      },
      "source": [
        "# define maximum length of a text\n",
        "max_len = 25"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbV1OazzSnr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "f691ab815dbc454094008c8fd85b7dfc",
            "11060b31405444bead662a981366ff80",
            "2e9205f57951491d942d15bb1787fddf",
            "6627dea468a9453aab6b8eb1b0b5925b",
            "4a9c76f717a944a1b5ae0fcb76449563",
            "6198969e50a741c39f714d33a807a77c",
            "c0ca4e7ce98e4969bc67f6f8e3b7d55f",
            "8301b2d5efc04305aa36c3c8c3ac3636",
            "7fb25c50bff94798874baa2dcd532d83",
            "ecbc5dcdf64c432fb42bd8f76fffc9e2",
            "6d4e1b4e7d5a415da9c054e51b156221"
          ]
        },
        "outputId": "1932407a-b730-4f59-e2bf-eba8d771381b"
      },
      "source": [
        "# library for progress bar\n",
        "from tqdm import notebook\n",
        "\n",
        "# create an empty list to save integer sequence\n",
        "sent_id = []\n",
        "\n",
        "# iterate over each tweet\n",
        "for i in notebook.tqdm(range(len(text))):\n",
        "\n",
        "  encoded_sent = tokenizer.encode(text[i],\n",
        "                                  add_special_tokens = True,\n",
        "                                  max_length = max_len,\n",
        "                                  truncation = True,\n",
        "                                  pad_to_max_length='right')\n",
        "\n",
        "  # saving integer sequence to a list\n",
        "  sent_id.append(encoded_sent)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/14640 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f691ab815dbc454094008c8fd85b7dfc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVgp93PgwLg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59bfa39b-22d9-4517-db5f-43938423a3c1"
      },
      "source": [
        "print(\"Integer Sequence:\",sent_id[0])"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer Sequence: [101, 2054, 2056, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k73WKt0NxpeC"
      },
      "source": [
        "# create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# for each sentence...\n",
        "for sent in sent_id:\n",
        "  att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "  # store the attention mask for this sentence.\n",
        "  attention_masks.append(att_mask)"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YONLj9J9AXQN"
      },
      "source": [
        "##3.4 Training and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqg2GTsqxpuW"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(sent_id, labels, random_state=2018, test_size=0.1, stratify=labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.1, stratify=labels)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y42CmxNaAsbZ"
      },
      "source": [
        "##3.5 Define Dataloaders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "033DKuEizSuP"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPnDd5SCzWS6"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "#Dataset wrapping tensors.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "#define a sampler for sampling the data during training\n",
        "  #random sampler samples randomly from a dataset\n",
        "  #sequential sampler samples sequentially, always in the same order\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "#represents a iterator over a dataset. Supports batching, customized data loading order\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "#Dataset wrapping tensors.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "\n",
        "#define a sequential sampler\n",
        "#This samples data in a sequential order\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "\n",
        "#create a iterator over the dataset\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGFO9vX1WD5-"
      },
      "source": [
        "#create an iterator object\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "#loads batch data\n",
        "sent_id, mask, target=next(iterator)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek5ie3hqF7Fk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b877db1-95ff-421d-a1be-b4fece808504"
      },
      "source": [
        "sent_id.shape"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ88suqBjeuo"
      },
      "source": [
        "#pass inputs to the model\n",
        "outputs = bert(sent_id, attention_mask=mask)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WleBnOAn5V7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426d0d8a-5c66-4f43-ed5b-82ed89ce163d"
      },
      "source": [
        "# hidden states\n",
        "hidden_states = outputs[0]\n",
        "\n",
        "# [CLS] hidden state\n",
        "CLS_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of Hidden States:\",hidden_states.shape)\n",
        "print(\"Shape of CLS Hidden State:\",CLS_hidden_state.shape)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Hidden States: torch.Size([32, 25, 768])\n",
            "Shape of CLS Hidden State: torch.Size([32, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb189wFSR0cE"
      },
      "source": [
        "#4. Model Finetuning\n",
        "\n",
        "*The pretrained model is trained on the general domain corpus. So, finetuning the pretrained model helps in the capturing the domain specific features from our custom dataset*\n",
        "\n",
        "\n",
        "Every pretrained model is trained using 2 different layers : **BackBone and Head**\n",
        "\n",
        "* Backbone refers to the pretrained model architecture\n",
        "* Head refers to the dense layer added on top of backbone. Generally, this layer is used for the classification tasks.\n",
        "\n",
        "Hence, we can finetune the pretrained model in 2 ways\n",
        "\n",
        "**1. Fine-Tuning only Head (or Dense Layer)**\n",
        "\n",
        "1.1  CLS token\n",
        "\n",
        "1.2  Hidden states\n",
        "\n",
        "\n",
        "**2. Fine-Tuning both Backbone & Head**\n",
        "\n",
        "1.1  CLS token\n",
        "\n",
        "1.2  Hidden states\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml6av5LqA24e"
      },
      "source": [
        "### 4.1 Approach: Fine-Tuning Only Head\n",
        "\n",
        "As the name suggests, in this approach, we freeze the backbone and train only the head or dense layer.\n",
        "\n",
        "### Steps to Follow\n",
        "\n",
        "1. Turn off Gradients\n",
        "\n",
        "2. Define Model Architecture\n",
        "\n",
        "3. Define Optimizer and Loss\n",
        "\n",
        "4. Define Train and Evaluate\n",
        "\n",
        "5. Train the model\n",
        "\n",
        "6. Evaluate the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDpxm52C5mpe"
      },
      "source": [
        "# turn off the gradient of all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kF7mh9TM_Rl"
      },
      "source": [
        "##4.2 Define Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RIDAa4NF5m5"
      },
      "source": [
        "#importing nn module\n",
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "\n",
        "    #define the layers and wrappers used by model\n",
        "    def __init__(self, bert):\n",
        "\n",
        "      #constructor\n",
        "      super(classifier, self).__init__()\n",
        "\n",
        "      #bert model\n",
        "      self.bert = bert\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "      #dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,3)\n",
        "\n",
        "      #dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      #relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model\n",
        "      all_hidden_states, cls_hidden_state = self.bert(sent_id, attention_mask=mask)\n",
        "\n",
        "      #pass CLS hidden state to dense layer\n",
        "      x = self.fc1(cls_hidden_state)\n",
        "\n",
        "      #Apply ReLU activation function\n",
        "      x = self.relu(x)\n",
        "\n",
        "      #Apply Dropout\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      #pass input to the output layer\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      #apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb6z3HDPF5lA"
      },
      "source": [
        "#create the model\n",
        "model = classifier(bert)\n",
        "\n",
        "#push the model to GPU, if available\n",
        "model = model.to(device)"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9R5XajGF5jA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f9bf98-7368-49a5-b7de-55baec671a72"
      },
      "source": [
        "#model architecture\n",
        "model"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fxTyKbRUGC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d69baa6-3eb2-496d-eb52-654107f5742d"
      },
      "source": [
        "# push the tensors to GPU\n",
        "sent_id = sent_id.to(device)\n",
        "mask = mask.to(device)\n",
        "target = target.to(device)\n",
        "\n",
        "# pass inputs to the model\n",
        "outputs = model(sent_id, mask)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of cls_hidden_state: <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLwIPXWNWg4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9a6a0d-66e2-4eee-97f7-d4031e479f11"
      },
      "source": [
        "# understand outputs\n",
        "print((outputs))"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.3282, -1.0756, -0.9315],\n",
            "        [-1.3030, -1.0946, -0.9324],\n",
            "        [-1.4058, -1.0322, -0.9198],\n",
            "        [-1.2214, -1.0380, -1.0469],\n",
            "        [-1.3880, -1.0370, -0.9266],\n",
            "        [-1.3085, -1.0664, -0.9531],\n",
            "        [-1.2624, -1.0469, -1.0051],\n",
            "        [-1.3384, -1.1119, -0.8945],\n",
            "        [-1.2391, -1.1167, -0.9597],\n",
            "        [-1.1817, -0.9833, -1.1421],\n",
            "        [-1.3947, -0.9977, -0.9588],\n",
            "        [-1.3037, -1.1415, -0.8937],\n",
            "        [-1.3811, -1.0700, -0.9022],\n",
            "        [-1.3060, -1.0372, -0.9817],\n",
            "        [-1.4111, -1.0233, -0.9245],\n",
            "        [-1.3181, -1.1193, -0.9018],\n",
            "        [-1.3575, -1.0890, -0.9011],\n",
            "        [-1.3777, -1.0666, -0.9072],\n",
            "        [-1.3776, -1.0754, -0.8998],\n",
            "        [-1.4309, -1.0931, -0.8540],\n",
            "        [-1.3574, -1.1217, -0.8748],\n",
            "        [-1.3464, -1.1396, -0.8678],\n",
            "        [-1.3556, -1.0157, -0.9675],\n",
            "        [-1.3656, -1.0801, -0.9034],\n",
            "        [-1.3540, -1.0749, -0.9151],\n",
            "        [-1.2885, -1.0548, -0.9781],\n",
            "        [-1.2921, -1.0158, -1.0128],\n",
            "        [-1.3352, -1.0248, -0.9728],\n",
            "        [-1.2612, -1.1372, -0.9264],\n",
            "        [-1.3356, -0.9909, -1.0057],\n",
            "        [-1.2737, -1.0663, -0.9783],\n",
            "        [-1.3747, -1.0582, -0.9163]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFJoc1aGYN1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96532a6d-1125-495b-97f1-e0de2e1652be"
      },
      "source": [
        "# no. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 395,267 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOTdl4RZNHk4"
      },
      "source": [
        "## 4.3 Define Optimizer and Loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7fjPGyQaVw"
      },
      "source": [
        "# Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Op_QSrUvem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "0169f50e-199e-402a-ed56-7ba8cb1390ef"
      },
      "source": [
        "# understand the class distribution\n",
        "keys=['0','1','2']\n",
        "\n",
        "# set figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "# plot bat chart\n",
        "plt.bar(keys,class_counts)\n",
        "\n",
        "# set title\n",
        "plt.title('Class Distribution')"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 209
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpluCEUzijp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "facef3d6-1d00-4009-8587-c9e0740b6118"
      },
      "source": [
        "#library for array processing\n",
        "import numpy as np\n",
        "\n",
        "#library for computing class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_labels), y= labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [0.53170625 1.57470152 2.06517139]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJuWGiqF5eM"
      },
      "source": [
        "# converting a list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# transfer to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqtirPVDg8aA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2a0c11-605a-42ef-d83e-970ec8331aee"
      },
      "source": [
        "#compute the loss\n",
        "loss = cross_entropy(outputs, target)\n",
        "print(\"Loss:\",loss)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(1.1607, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Sx2rgyu4Aj"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "# compute time in hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    # round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds = elapsed_rounded))"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJixsg1XzHCA"
      },
      "source": [
        "## 4.4 Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFPILeF9Spxe"
      },
      "source": [
        "The deep learning model is trained in the form of epochs where in each epoch consists of several batches.\n",
        "\n",
        "During training, for each batch, we need to\n",
        "\n",
        "1. Perform Forward Pass\n",
        "2. Compute Loss\n",
        "3. Backpropagate Loss\n",
        "4. Update Weights\n",
        "\n",
        "Where as during evaluation, for each batch, we need to\n",
        "\n",
        "1. Perform forward pass\n",
        "2. Compute loss\n",
        "\n",
        "```\n",
        "Training: Epoch -> Batch -> Forward Pass -> Compute loss -> Backpropagate loss -> Update weights\n",
        "```\n",
        "\n",
        "```\n",
        "Evaluation: Epoch -> Batch -> Forward Pass -> Compute loss\n",
        "```\n",
        "\n",
        "Hence, for each epoch, we have a training phase and a validation phase. After each batch we need to:\n",
        "\n",
        "**Training phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "\n",
        "2. Unpack our data inputs and labels\n",
        "\n",
        "3. Clear out the gradients calculated in the previous pass.\n",
        "\n",
        "4. Forward pass (feed input data through the network)\n",
        "\n",
        "5. Backward pass (backpropagation)\n",
        "\n",
        "6. Update parameters with optimizer.step()\n",
        "\n",
        "7. Track variables for monitoring progress\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgIYKxjv2Wv0"
      },
      "source": [
        "#define a function for training the model\n",
        "def train():\n",
        "\n",
        "  print(\"\\nTraining.....\")\n",
        "\n",
        "  #set the model on training phase - Dropout layers are activated\n",
        "  model.train()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds=[]\n",
        "\n",
        "  #for every batch\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Progress update after every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids\n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Always clear any previously calculated gradients before performing a\n",
        "    # backward pass. PyTorch doesn't do this automatically.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Perform a forward pass. This returns the model predictions\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    #compute the loss between actual and predicted values\n",
        "    loss =  cross_entropy(preds, labels)\n",
        "\n",
        "    # Accumulate the training loss over all of the batches so that we can\n",
        "    # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "    # single value; the `.item()` function just returns the Python value\n",
        "    # from the tensor.\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # Perform a backward pass to calculate the gradients.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "    # modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    #The model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    #Accumulate the model predictions of each batch\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  #compute the training loss of a epoch\n",
        "  avg_loss     = total_loss / len(train_dataloader)\n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SF3wrDuSwpj"
      },
      "source": [
        "\n",
        "**Evaluation phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "\n",
        "2. Unpack our data inputs and labels\n",
        "\n",
        "3. Forward pass (feed input data through the network)\n",
        "\n",
        "4. Compute loss on our validation data\n",
        "\n",
        "5. Track variables for monitoring progress\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPKfeGlC5_WE"
      },
      "source": [
        "#define a function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "  print(\"\\nEvaluating.....\")\n",
        "\n",
        "  #set the model on training phase - Dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize the loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  #for each batch\n",
        "  for step,batch in enumerate(validation_dataloader):\n",
        "\n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids\n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # Perform a forward pass. This returns the model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      #compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      # Accumulate the validation loss over all of the batches so that we can\n",
        "      # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "      # single value; the `.item()` function just returns the Python value\n",
        "      # from the tensor.\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      #The model predictions are stored on GPU. So, push it to CPU\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "\n",
        "      #Accumulate the model predictions of each batch\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  #compute the validation loss of a epoch\n",
        "  avg_loss = total_loss / len(validation_dataloader)\n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7d_XacvNgyU"
      },
      "source": [
        "##4.5 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_sj66daFTAQ"
      },
      "source": [
        "#Assign the initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "#create a empty list to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n....... epoch {:} / {:} .......'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    #accumulate training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNhFJ0DANldu"
      },
      "source": [
        "##4.6 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4OPuAKj6Kiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fa96fd-d450-47a7-d4d9-9605666368d7"
      },
      "source": [
        "# load weights of best model\n",
        "path='saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coqwKsGeFTDW"
      },
      "source": [
        "# get the model predictions on the validation data\n",
        "# returns 2 elements- Validation loss and Predictions\n",
        "valid_loss, preds = evaluate()\n",
        "print(valid_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DehF35geFTIB"
      },
      "source": [
        "# Converting the log(probabities) into a classes\n",
        "# Choosing index of a maximum value as class\n",
        "y_pred = np.argmax(preds,axis=1)\n",
        "\n",
        "# actual labels\n",
        "y_true = validation_labels"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXjiXdk5Co8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb1a049-6409-462d-efa1-8fbc14b13a98"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.74      0.81       918\n",
            "           1       0.50      0.65      0.56       310\n",
            "           2       0.65      0.80      0.72       236\n",
            "\n",
            "    accuracy                           0.73      1464\n",
            "   macro avg       0.68      0.73      0.70      1464\n",
            "weighted avg       0.77      0.73      0.74      1464\n",
            "\n"
          ]
        }
      ]
    }
  ]
}